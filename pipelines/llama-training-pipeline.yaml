###############################################################################
# LLaMA Training Pipeline (Kubeflow/Argo Workflow)
# DAG: ë°ì´í„°ì „ì²˜ë¦¬ â†’ ëª¨ë¸í•™ìŠµ â†’ ëª¨ë¸í‰ê°€
# ê° ë‹¨ê³„ì— insight-trace ì‚¬ì´ë“œì¹´ í¬í•¨
###############################################################################
apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  generateName: llama-training-pipeline-
  namespace: kubeflow-user-example-com
  labels:
    app: llama-pipeline
    workload-type: text
    framework: pytorch
spec:
  entrypoint: llama-pipeline

  # ê³µìœ  ë³¼ë¥¨ (ë‹¨ê³„ ê°„ ë°ì´í„° ì „ë‹¬)
  volumeClaimTemplates:
  - metadata:
      name: pipeline-data
    spec:
      accessModes: ["ReadWriteOnce"]
      resources:
        requests:
          storage: 5Gi

  # DAG ì •ì˜
  templates:
  #===========================================================================
  # Main DAG Pipeline
  #===========================================================================
  - name: llama-pipeline
    dag:
      tasks:
      # Step 1: ë°ì´í„° ì „ì²˜ë¦¬
      - name: preprocess
        template: preprocess-step

      # Step 2: ëª¨ë¸ í•™ìŠµ (ì „ì²˜ë¦¬ ì™„ë£Œ í›„)
      - name: train
        template: train-step
        dependencies: [preprocess]

      # Step 3: ëª¨ë¸ í‰ê°€ (í•™ìŠµ ì™„ë£Œ í›„)
      - name: evaluate
        template: evaluate-step
        dependencies: [train]

  #===========================================================================
  # Step 1: ë°ì´í„° ì „ì²˜ë¦¬
  #===========================================================================
  - name: preprocess-step
    metadata:
      labels:
        pipeline-step: preprocess
        workload-type: text
    podSpecPatch: |
      shareProcessNamespace: true
    sidecars:
    - name: insight-trace
      image: ketidevit2/insight-trace:latest
      imagePullPolicy: Always
      env:
      - name: POD_NAME
        valueFrom:
          fieldRef:
            fieldPath: metadata.name
      - name: POD_NAMESPACE
        valueFrom:
          fieldRef:
            fieldPath: metadata.namespace
      - name: NODE_NAME
        valueFrom:
          fieldRef:
            fieldPath: spec.nodeName
      - name: APOLLO_ENDPOINT
        value: "apollo-policy-server.keti.svc.cluster.local:50051"
      - name: PIPELINE_STEP
        value: "preprocess"
      - name: REPORT_INTERVAL
        value: "15s"
      resources:
        requests:
          cpu: "50m"
          memory: "64Mi"
      volumeMounts:
      - name: pipeline-data
        mountPath: /data
        readOnly: true
    container:
      image: python:3.11-slim
      command: [python3, -c]
      args:
      - |
        import time
        import sys
        import os

        sys.argv[0] = 'llama_data_preprocessor.py'

        print("=" * 60)
        print("[STEP 1/3] Data Preprocessing")
        print("=" * 60)
        print("Task: Tokenization & Data Preparation for LLaMA")

        os.makedirs('/data/processed', exist_ok=True)
        os.makedirs('/data/tokens', exist_ok=True)

        # ì „ì²˜ë¦¬ ë‹¨ê³„ ì‹œë®¬ë ˆì´ì…˜
        stages = ['load_dataset', 'tokenize', 'create_batches', 'save_processed']
        for i, stage in enumerate(stages):
            print(f"\n[{time.strftime('%H:%M:%S')}] Stage {i+1}/4: {stage}")

            # I/O ì‘ì—… ì‹œë®¬ë ˆì´ì…˜
            with open(f'/data/processed/{stage}.bin', 'wb') as f:
                f.write(os.urandom(5 * 1024 * 1024))  # 5MB

            time.sleep(30)  # 30ì´ˆì”© (ì´ 2ë¶„)

        # ìµœì¢… í† í° ë°ì´í„° ì €ì¥
        with open('/data/tokens/train_tokens.bin', 'wb') as f:
            f.write(os.urandom(20 * 1024 * 1024))  # 20MB

        print("\n" + "=" * 60)
        print("[STEP 1/3] Preprocessing COMPLETED")
        print("Output: /data/tokens/train_tokens.bin")
        print("=" * 60)

        # ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ëŒ€ê¸°
        time.sleep(60)
      resources:
        requests:
          cpu: "500m"
          memory: "512Mi"
      volumeMounts:
      - name: pipeline-data
        mountPath: /data

  #===========================================================================
  # Step 2: ëª¨ë¸ í•™ìŠµ
  #===========================================================================
  - name: train-step
    metadata:
      labels:
        pipeline-step: train
        workload-type: text
    podSpecPatch: |
      shareProcessNamespace: true
    sidecars:
    - name: insight-trace
      image: ketidevit2/insight-trace:latest
      imagePullPolicy: Always
      env:
      - name: POD_NAME
        valueFrom:
          fieldRef:
            fieldPath: metadata.name
      - name: POD_NAMESPACE
        valueFrom:
          fieldRef:
            fieldPath: metadata.namespace
      - name: NODE_NAME
        valueFrom:
          fieldRef:
            fieldPath: spec.nodeName
      - name: APOLLO_ENDPOINT
        value: "apollo-policy-server.keti.svc.cluster.local:50051"
      - name: PIPELINE_STEP
        value: "train"
      - name: REPORT_INTERVAL
        value: "15s"
      resources:
        requests:
          cpu: "50m"
          memory: "64Mi"
      volumeMounts:
      - name: pipeline-data
        mountPath: /data
        readOnly: true
    container:
      image: python:3.11-slim
      command: [python3, -c]
      args:
      - |
        import time
        import sys
        import os
        import random

        sys.argv[0] = 'llama_pytorch_trainer.py'

        print("=" * 60)
        print("[STEP 2/3] Model Training")
        print("=" * 60)
        print("Model: LLaMA-7B")
        print("Framework: PyTorch + HuggingFace")

        os.makedirs('/data/checkpoints', exist_ok=True)

        # ì „ì²˜ë¦¬ ë°ì´í„° í™•ì¸
        if os.path.exists('/data/tokens/train_tokens.bin'):
            print("âœ“ Preprocessed data found")
        else:
            print("âš  Using simulated data")

        EPOCHS = 3
        STEPS_PER_EPOCH = 20

        for epoch in range(EPOCHS):
            print(f"\n[Epoch {epoch+1}/{EPOCHS}]")
            epoch_loss = 0

            for step in range(STEPS_PER_EPOCH):
                loss = 2.0 - (epoch * 0.3) - (step * 0.02) + random.uniform(-0.05, 0.05)
                epoch_loss += loss

                # ì²´í¬í¬ì¸íŠ¸ ì €ì¥
                with open(f'/data/checkpoints/step_{epoch}_{step}.bin', 'wb') as f:
                    f.write(os.urandom(1024 * 1024))

                if step % 5 == 0:
                    print(f"  Step {step}/{STEPS_PER_EPOCH}: loss={loss:.4f}")

                time.sleep(5)  # 5ì´ˆì”©

            # ì—í­ ì²´í¬í¬ì¸íŠ¸
            ckpt_path = f'/data/checkpoints/llama_epoch_{epoch+1}.pt'
            with open(ckpt_path, 'wb') as f:
                f.write(os.urandom(50 * 1024 * 1024))  # 50MB
            print(f"  Checkpoint saved: {ckpt_path}")

        # ìµœì¢… ëª¨ë¸ ì €ì¥
        with open('/data/checkpoints/llama_final.pt', 'wb') as f:
            f.write(os.urandom(100 * 1024 * 1024))  # 100MB

        print("\n" + "=" * 60)
        print("[STEP 2/3] Training COMPLETED")
        print("Output: /data/checkpoints/llama_final.pt")
        print("=" * 60)

        time.sleep(60)
      resources:
        requests:
          cpu: "1000m"
          memory: "2Gi"
          nvidia.com/gpu: 1
        limits:
          cpu: "2000m"
          memory: "4Gi"
          nvidia.com/gpu: 1
      volumeMounts:
      - name: pipeline-data
        mountPath: /data

  #===========================================================================
  # Step 3: ëª¨ë¸ í‰ê°€
  #===========================================================================
  - name: evaluate-step
    metadata:
      labels:
        pipeline-step: evaluate
        workload-type: text
    podSpecPatch: |
      shareProcessNamespace: true
    sidecars:
    - name: insight-trace
      image: ketidevit2/insight-trace:latest
      imagePullPolicy: Always
      env:
      - name: POD_NAME
        valueFrom:
          fieldRef:
            fieldPath: metadata.name
      - name: POD_NAMESPACE
        valueFrom:
          fieldRef:
            fieldPath: metadata.namespace
      - name: NODE_NAME
        valueFrom:
          fieldRef:
            fieldPath: spec.nodeName
      - name: APOLLO_ENDPOINT
        value: "apollo-policy-server.keti.svc.cluster.local:50051"
      - name: PIPELINE_STEP
        value: "evaluate"
      - name: REPORT_INTERVAL
        value: "15s"
      resources:
        requests:
          cpu: "50m"
          memory: "64Mi"
      volumeMounts:
      - name: pipeline-data
        mountPath: /data
        readOnly: true
    container:
      image: python:3.11-slim
      command: [python3, -c]
      args:
      - |
        import time
        import sys
        import os
        import random

        sys.argv[0] = 'llama_model_evaluator.py'

        print("=" * 60)
        print("[STEP 3/3] Model Evaluation")
        print("=" * 60)
        print("Task: Evaluate LLaMA model performance")

        os.makedirs('/data/results', exist_ok=True)

        # ëª¨ë¸ ë¡œë“œ í™•ì¸
        model_path = '/data/checkpoints/llama_final.pt'
        if os.path.exists(model_path):
            print(f"âœ“ Model loaded: {model_path}")
        else:
            print("âš  Using simulated model")

        # í‰ê°€ ë©”íŠ¸ë¦­
        metrics = {
            'perplexity': random.uniform(15, 25),
            'bleu_score': random.uniform(0.3, 0.5),
            'rouge_l': random.uniform(0.4, 0.6),
            'accuracy': random.uniform(0.75, 0.90)
        }

        print("\nRunning evaluation...")
        for i in range(10):
            print(f"  Evaluating batch {i+1}/10...")
            time.sleep(10)  # 10ì´ˆì”©

        print("\n" + "=" * 60)
        print("Evaluation Results:")
        print("=" * 60)
        for metric, value in metrics.items():
            print(f"  {metric}: {value:.4f}")

        # ê²°ê³¼ ì €ì¥
        with open('/data/results/evaluation.json', 'w') as f:
            import json
            json.dump(metrics, f, indent=2)

        print("\n" + "=" * 60)
        print("[STEP 3/3] Evaluation COMPLETED")
        print("Output: /data/results/evaluation.json")
        print("=" * 60)
        print("\nğŸ‰ PIPELINE COMPLETED SUCCESSFULLY!")

        time.sleep(60)
      resources:
        requests:
          cpu: "500m"
          memory: "1Gi"
      volumeMounts:
      - name: pipeline-data
        mountPath: /data
